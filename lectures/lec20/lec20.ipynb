{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904f660",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "TEMPLATE = 'seaborn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 20 ‚Äì Modeling and Linear Regression\n",
    "\n",
    "## DSC 80, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Modeling.\n",
    "- Case study: Restaurant tips üßë‚Äçüç≥.\n",
    "- Regression in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c279906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82dd8c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/DSLC.png' width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5929c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "So far this quarter, we've learned how to:\n",
    "\n",
    "- Extract information from tabular data using `pandas` and regular expressions.\n",
    "- Clean data so that it best represents a data generating process.\n",
    "    - Missingness analyses and imputation.\n",
    "- Collect data from the internet through scraping and APIs, and parse it using BeautifulSoup.\n",
    "- Perform exploratory data analysis through aggregation, visualization, and the computation of summary statistics like TF-IDF.\n",
    "- Infer about the relationships between samples and populations through hypothesis and permutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a3db3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We haven't** learned how to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cdcff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58771e16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Data generating process**: A real-world phenomena that we are interested in studying.\n",
    "    - *Example:* Every year, city employees are hired and fired, earn salaries and benefits, etc.\n",
    "    - Unless we work for the city, we can't observe this process directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b13c48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Model**: A theory about the data generating process.\n",
    "    - *Example:* If an employee is $X$ years older than average, then they will make \\$100,000 in salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400af90c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Fit Model**: A model that is learned from a particular set of observations, i.e. training data.\n",
    "    - *Example:* If an employee is 5 years older than average, they will make \\$100,000 in salary.\n",
    "    - How is this estimate determined? What makes it \"good\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d209c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goals of modeling\n",
    "\n",
    "1. To make accurate **predictions** regarding **unseen data** drawn from the data generating process.\n",
    "    - Given this dataset of past UCSD data science students' salaries, can we predict your future salary? (regression)\n",
    "    - Given this dataset of images, can we predict if this new image is of a dog, cat, or zebra? (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c9040",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. To make **inferences** about the structure of the data generating process, i.e. to understand complex phenomena.\n",
    "    - Is there a linear relationship between the heights of children and the heights of their biological mothers?\n",
    "    - The weights of smoking and non-smoking mothers' babies babies in my _sample_ are different ‚Äì how _confident_ am I that this difference exists in the _population_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a0b01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/taxonomy.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17359bce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Of the two focuses of models, we will focus on **prediction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f505715",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the above taxonomy, we will focus on **supervised learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397636e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea8278",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **feature** is a measurable property of a phenomenon being observed.\n",
    "    - Other terms for \"feature\" include \"(explanatory) variable\" and \"attribute\".\n",
    "    - Typically, features are the _inputs_ to models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3bb20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DataFrames, features typically correspond to **columns**, while rows typically correspond to different individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa324b9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* There are two types of features:\n",
    "    * Features that come as part of a dataset, e.g. weight and height.\n",
    "    * Features that we **create**, e.g. $\\text{BMI} = \\frac{\\text{weight (kg)}}{\\text{[height (m)]}^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61dd85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: TF-IDF is a **feature** we've created that summarizes documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Restaurant tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff409ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About the data\n",
    "\n",
    "What features does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72476546",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly (and seaborn)!\n",
    "tips = px.data.tips()\n",
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63ac84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5e9bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal:** Given various information about a table at a restaurant, we want to predict the **tip** that a server will earn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82b254",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Why** might a server be interested in doing this?\n",
    "    - To determine which tables are likely to tip the most (inference).\n",
    "    - To predict earnings over the next month (prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cd857",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93071bfc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most natural feature to look at first is `'total_bill'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7dd65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we should explore the relationship between `'total_bill'` and `'tip'`, as well as the distributions of both columns individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fe42a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we do so, try to describe each distribution **in words**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fb889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot(kind='scatter', \n",
    "          x='total_bill', y='tip',\n",
    "          title='Tip vs. Total Bill',\n",
    "          template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot(kind='hist', \n",
    "          x='total_bill', \n",
    "          title='Distribution of Total Bill',\n",
    "          nbins=50,\n",
    "          template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot(kind='hist', \n",
    "          x='tip', \n",
    "          title='Distribution of Tip',\n",
    "          nbins=50,\n",
    "          template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518624a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observations\n",
    "|`'total_bill'`|`'tip'`|\n",
    "|---|---|\n",
    "|Right skewed|Right skewed|\n",
    "|Mean around \\$20|Mean around \\$3|\n",
    "|Mode around \\$16|Possibly bimodal at \\\\$2 and \\\\$3?|\n",
    "|No particularly large bills|Large outliers?|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ab1f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/convo.png' width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ef9bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #1: Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88688c4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's start simple, by ignoring all features. Suppose our model assumes every tip is given by a constant dollar amount:\n",
    "\n",
    "$$\\text{tip} = h^{\\text{true}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356eb26",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Model**: There is a single tip amount $h^{\\text{true}}$ that all customers pay.\n",
    "    - Correct? No!\n",
    "    - Useful? Perhaps. An estimate of $h^{\\text{true}}$, denoted by $h^*$, can allow us to predict future tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82019588",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The true **parameter** $h^{\\text{true}}$ is determined by the universe (i.e. the data generating process).\n",
    "    - We can't observe the true parameter; we need to **estimate it from the data**.\n",
    "    - Hence, our estimate depends on our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc1f4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/box.png\" width=20%>George Box</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce3981",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>\"All models are wrong, but some are useful.\"</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74a5e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> \"Since all models are wrong the scientist cannot obtain a \"correct\" one by excessive elaboration. On the contrary following William of Occam he should **seek an economical description of natural phenomena**. Just as the ability to devise simple but evocative models is the signature of the great scientist so overelaboration and overparameterization is often the mark of mediocrity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71257eb0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> \"Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc3074",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating $h^{\\text{true}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f4ab6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are several ways we _could_ estimate $h^{\\text{true}}$.\n",
    "    - We could use domain knowledge (e.g. everyone clicks the \\$1 tip option when buying coffee)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c58a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- From DSC 40A, we already know one way:\n",
    "    - **Choose a loss function**, which measures how \"good\" a single prediction is.\n",
    "    - **Minimize empirical risk**, to find the best estimate for the dataset that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ebdca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical risk minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b4ec98",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Depending on which loss function we choose, we will end up with different $h^*$ (which are estimates of $h^{\\text{true}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68eacb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we choose **squared loss**, then our empirical risk is **mean squared error**:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i = 1}^n ( y_i - h )^2 \\overset{\\text{calculus}}\\implies h^* = \\text{mean}(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0523b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we choose **absolute loss**, then our empirical risk is **mean absolute error**:\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i = 1}^n | y_i - h | \\overset{\\text{algebra}}\\implies h^* = \\text{median}(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c7e4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The mean tip\n",
    "\n",
    "Let's suppose we choose squared loss, meaning that $h^* = \\text{mean}(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tip = tips['tip'].mean()\n",
    "mean_tip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682f5f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's visualize this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad889eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, the code to visualize a scatter plot and a line\n",
    "# in plotly is not all that concise.\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tips['total_bill'], \n",
    "    y=tips['tip'], \n",
    "    mode='markers',\n",
    "    name='Original Data')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 60],\n",
    "    y=[mean_tip, mean_tip],\n",
    "    mode='lines',\n",
    "    name='Constant Prediction (Mean)'\n",
    "))\n",
    "\n",
    "fig.update_layout(showlegend=True, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip',\n",
    "                  template=TEMPLATE)\n",
    "fig.update_xaxes(range=[0, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8029d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that to make predictions, this model ignores total bill (and all other features), and predicts the same tip for all tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3d4b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The quality of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad29ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How can we quantify how **good** this constant prediction is at predicting tips in our **training data** ‚Äì that is, the data we used to fit the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5361c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One answer**: use the mean squared error. If $y_i$ represents the $i$th actual value and $H(x_i)$ represents the $i$th predicted value, then:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((tips['tip'] - mean_tip) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same! A fact from 40A.\n",
    "np.var(tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216250ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Issue: The units of MSE are \"dollars squared\", which are a little hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308abe7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866e16a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Often, to measure the quality of a regression model's predictions, we will use the **root mean squared error (RMSE)**:\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee926e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The units of the RMSE are the same as the units of the original $y$ values ‚Äì dollars, in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36504e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: Minimizing MSE is the same as minimizing RMSE; the constant tip $h^*$ that minimizes MSE is the same $h^*$ that minimizes RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c5b96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing and storing the RMSE\n",
    "\n",
    "Since we'll compute the RMSE for our future models too, we'll define a function that can compute it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2e2e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's compute the RMSE of our constant tip's predictions, and store it in a dictionary that we can refer to later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(tips['tip'], mean_tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c532f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: Since the mean minimizes RMSE for the constant model, it is **impossible** to change the `mean_tip` argument above to another number and yield a **lower** RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7060d61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #2: Simple linear regression using total bill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26459a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We haven't yet used any of the **features** in the dataset. The first natural feature to look at is `'total_bill'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b073ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e44983",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can fit a **simple linear model** to predict tips as a function of total bill:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ddfca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is a reasonable thing to do, because total bills and tips appeared to be linearly associated when we visualized them on a scatter plot a few slides ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382ee3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Simple linear regression\n",
    "\n",
    "A simple linear regression model is a linear model with a single feature, as we have here. For any total bill $x_i$, the predicted tip $H(x_i)$ is given by\n",
    "\n",
    "$$H(x_i) = w_0 + w_1x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4d412",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we determine which intercept, $w_0$, and slope, $w_1$, to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0359f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One answer**: Pick the $w_0$ and $w_1$ that minimize **mean squared error**. If $x_i$ and $y_i$ correspond to the $i$th total bill and tip, respectively, then:\n",
    "\n",
    "$$\\begin{align*}\\text{MSE} &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2\n",
    "\\\\ &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - w_0 - w_1x_i \\big)^2\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19b408",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: The lower the MSE on our training data is, the \"better\" the model fits the training data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c5f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical risk minimization, by hand\n",
    "\n",
    "$$\\begin{align*}\\text{MSE} &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - w_0 - w_1x_i \\big)^2\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d816374",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DSC 40A, you found the formulas for the best intercept, $w_0^*$, and the best slope, $w_1^*$, through calculus. \n",
    "    - The resulting line, $H(x_i) = w_0^* + w_1^* x_i$, is called the **line of best fit**, or the **regression line**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09be71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Specifically, if $r$ is the correlation coefficient, $\\sigma_x$ and $\\sigma_y$ are the standard deviations of $x$ and $y$, and $\\bar{x}$ and $\\bar{y}$ are the means of $x$ and $y$, then:\n",
    "\n",
    "$$w_1^* = r \\cdot \\frac{\\sigma_y}{\\sigma_x}$$\n",
    "\n",
    "$$w_0^* = \\bar{y} - w_1^* \\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8922bec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ed0be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `sklearn`\n",
    "\n",
    "<center><img src='imgs/sklearn.png' width=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ce095",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` (scikit-learn) implements many common steps in the feature and model creation pipeline.\n",
    "    - It is **widely** used throughout [industry](https://scikit-learn.org/stable/testimonials/testimonials.html#:~:text=It%20is%20very%20widely%20used,very%20approachable%20and%20very%20powerful.) and academia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6526c66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It interfaces with `numpy` arrays, and to an extent, `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8c92d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Huge benefit: the [documentation online](https://scikit-learn.org/stable/modules/classes.html) is excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0279c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `LinearRegression` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d5989",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` comes with several subpackages, including `linear_model` and `tree`, each of which contains several classes of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5ef1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll start with the `LinearRegression` class from `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5fb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ec61c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: From [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression), we have:\n",
    "\n",
    "> LinearRegression fits a linear model with coefficients w = (w1, ‚Ä¶, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72db81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In other words, `LinearRegression` minimizes mean squared error by default! (Per the documentation, it also includes an intercept term by default.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17553ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d6df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55feff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we must instantiate a `LinearRegression` object and fit it. By calling `fit`, we are saying \"minimize mean squared error on this dataset and find $w^*$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Note that there are two arguments to fit ‚Äì X and y!\n",
    "# (It is not necessary to write X= and y=)\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983b9bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After fitting, we can access $w^*$ ‚Äì that is, the best slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05170d2f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These coefficients tell us that the \"best way\" (according to squared loss) to make tip predictions using a linear model is using:\n",
    "\n",
    "$$\\text{predicted tip} = 0.92 + 0.105 \\cdot \\text{total bill}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0bde1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This model **assumes** people tip by:\n",
    "- Tipping a constant 92 cents.\n",
    "- Tipping 10.5\\% for every dollar spent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad774c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize this model, along with our previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0171c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 60],\n",
    "    y=model.predict([[0], [60]]),\n",
    "    mode='lines',\n",
    "    name='Linear: Total Bill Only'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1d94a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Visually, our linear model _seems_ to be a better fit for our dataset than our constant model.\n",
    "- Can we quantify whether or not it is better? \n",
    "- **Does it better reflect reality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776c605",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions\n",
    "\n",
    "Fit `LinearRegression` objects also have a `predict` method, which can be used to predict tips for any total bill, new or old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input to model.predict **must** be a 2D list/array.\n",
    "model.predict([[15],\n",
    "               [4],\n",
    "               [100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ed83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array(\n",
    "    [15, 4, 100]\n",
    ").reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc0fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing models\n",
    "\n",
    "If we want to compute the RMSE of our model on the training data, we need to find its predictions on every row in the training data, `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3483d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = model.predict(tips[['total_bill']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d84da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319bc0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The RMSE of our simple linear model is **lower** than that of our constant model, which means it does a **better job** at modeling the training data than our constant model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733240f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is impossible for the RMSE **on the training data** to increase as we add more features to the same model. However, the RMSE may increase on **unseen data** by adding more features; we'll discuss this idea more soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037400cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #3: Multiple linear regression using total bill and table size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c1c58",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are still many features in `tips` we haven't touched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb05d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd72f28",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try using another feature ‚Äì table size. Such a model would predict tips using:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b57e40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple linear regression\n",
    "\n",
    "To find the optimal parameters $w^*$, we will again use `sklearn`'s `LinearRegression` class. The code is not all that different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce651f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ab753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.intercept_, model_two.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e18991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.predict([[25, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6967c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does this model _look_ like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9f722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plane of best fit ‚úàÔ∏è\n",
    "\n",
    "Here, we must draw a 3D scatter plot and plane, with one axis for total bill, one axis for table size, and one axis for tip. The code below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z = model_two.intercept_ + model_two.coef_[0] * XX + model_two.coef_[1] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z, colorscale='Oranges')\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=tips['total_bill'], \n",
    "                           y=tips['size'], \n",
    "                           z=tips['tip'], mode='markers', marker = {'color': '#656DF1'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='total bill',\n",
    "    yaxis_title='table size',\n",
    "    zaxis_title='tip'),\n",
    "  title='Tip vs. Total Bill and Table Size',\n",
    "    width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ffbb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing models, again \n",
    "\n",
    "How does our two-feature linear model stack up to our single feature linear model and our constant model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f85ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The RMSE of our two-feature model is the lowest of the three models we've looked at so far, but not by much. We didn't **gain** much by adding table size to our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49078a69",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's also not clear whether table sizes are practically useful in predicting tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ef578",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "- We built three models:\n",
    "    - A constant model: $\\text{predicted tip} = h^*$.\n",
    "    - A simple linear regression model: $\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill}$.\n",
    "    - A multiple linear regression model: $\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill} + w_2^* \\cdot \\text{table size}$.\n",
    "- As we added more features, our RMSEs decreased.\n",
    "    - This was guaranteed to happen, since we were only looking at our training data.\n",
    "- It is not clear that the final linear model is actually \"better\"; it doesn't seem to **reflect reality** better than the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fb660",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- A model is an assumption about a data generating process.\n",
    "    - Models can be used for both inference and prediction.\n",
    "    - All models are wrong (because they are oversimplifications of reality), but even simple models can be useful in practice.\n",
    "- A feature is a measurable property of a phenomenon being observed, typically used as input to a model.\n",
    "- The `LinearRegression` class in `sklearn.linear_model` provides an implementation of least squares linear regression that works with multiple features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dad56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- How do we _encode_ categorical features?\n",
    "    - What if they're nominal?\n",
    "    - What if they're ordinal?\n",
    "- How do we _create_ good features?\n",
    "- How else can we compare linear models?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
