{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904f660",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 19 â€“ Bag of Words, TF-IDF\n",
    "\n",
    "## DSC 80, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Bag of words ðŸ’°.\n",
    "    - Cosine similarity.\n",
    "- TF-IDF.\n",
    "    - Example: State of the Union addresses ðŸŽ¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4295f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('https://transcal.s3.amazonaws.com/public/export/san-diego-2021.csv')\n",
    "util.anonymize_names(salaries)\n",
    "\n",
    "jobtitles = salaries['Job Title']\n",
    "jobtitles = jobtitles[jobtitles.notna()]\n",
    "jobtitles = (\n",
    "    jobtitles\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\bto\\b|\\bthe\\b|\\bfor\\b', '', regex=True)\n",
    "    .str.replace('[^A-Za-z0-9 ]', ' ', regex=True)\n",
    "    .str.replace(' +', ' ', regex=True)               # ' +' matches 1 or more occurrences of a space.\n",
    "    .str.strip()                                      # Removes leading/trailing spaces if present.\n",
    ")\n",
    "\n",
    "unique_words = pd.Series(jobtitles.str.split().sum()).value_counts()\n",
    "\n",
    "# Created using a dictionary to avoid a \"DataFrame is highly fragmented\" warning.\n",
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = jobtitles.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(jobtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff5ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of words ðŸ’°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c6106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: San Diego employee salaries\n",
    "\n",
    "Recall, we're working with a (real) dataset of salary data for all San Diego city employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ff104",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "jobtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26409a8d",
   "metadata": {},
   "source": [
    "Our goal is to **quantify** how similar two job titles are; so far, our metric has been the number of **shared words** between the two titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b462b66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A counts matrix\n",
    "\n",
    "Let's create a \"counts\" matrix, such that:\n",
    "- there is 1 row per job title,\n",
    "- there is 1 column per **unique** word that is used in job titles, and\n",
    "- the value in row `title` and column `word` is the number of occurrences of `word` in `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769612f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: What job titles are most similar to `'deputy fire chief'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d14948",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember, our idea was to count the number of shared words between two job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66e423",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We now have access to `counts_df`, which contains a row vector for each job title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83892e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How can we use it to count the number of shared words between two job titles, i.e. the **similarity** of two job titles?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abeb42b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To start, let's compare the row vectors for `'deputy fire chief'` and `'fire battalion chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f1fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = counts_df.loc['deputy fire chief'].iloc[0]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c56a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbc = counts_df.loc['fire battalion chief'].iloc[0]\n",
    "fbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbbcd2",
   "metadata": {},
   "source": [
    "We can stack these two vectors horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557eb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = (\n",
    "    pd.concat([dfc, fbc], axis=1)\n",
    "    .sort_values(by=['deputy fire chief', 'fire battalion chief'], ascending=False)\n",
    "    .head(10)\n",
    "    .T\n",
    ")\n",
    "\n",
    "pair_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1144b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to measure how similar the above two vectors are is through their **dot product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pair_counts.iloc[0] * pair_counts.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829862d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, since both vectors consist only of 1s and 0s, the dot product is equal to the **number of shared words** between the two job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efce65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Dot product\n",
    "\n",
    "- Recall, if $\\vec{a} = \\begin{bmatrix} a_1 & a_2 & ... & a_n \\end{bmatrix}^T$ and $\\vec{b} = \\begin{bmatrix} b_1 & b_2 & ... & b_n \\end{bmatrix}^T$ are two vectors, then their **dot product** $\\vec{a} \\cdot \\vec{b}$ is defined as:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + ... + a_nb_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db440089",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The dot product also has a **geometric** interpretation. If $|\\vec{a}|$ and $|\\vec{b}|$ are the $L_2$ norms (lengths) of $\\vec{a}$ and $\\vec{b}$, and $\\theta$ is the angle between $\\vec{a}$ and $\\vec{b}$, then:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = |\\vec{a}| |\\vec{b}| \\cos \\theta$$\n",
    "\n",
    "<center><img src='imgs/dot-prod.png' width=20%>(<a href=\"https://byjus.com/physics/scalar-and-vector-products/\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2388b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\cos \\theta$ is equal to its maximum value (1) when $\\theta = 0$, i.e. when $\\vec{a}$ and $\\vec{b}$ point in the same direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a70d25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ðŸš¨ **Key idea: The more similar two unit vectors are, the larger their dot product is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d041d25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing similarities\n",
    "\n",
    "To find the job title that is most similar to `'deputy fire chief'`, we can compute the dot product of the `'deputy fire chief'` word vector with all other titles' word vectors, and find the title with the highest dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff15953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55504644",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab9f8f",
   "metadata": {},
   "source": [
    "To do so, we can apply `np.dot` to each row that doesn't correspond to `'deputy fire chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a887fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = (\n",
    "    counts_df[counts_df.index != 'deputy fire chief']\n",
    "    .apply(lambda s: np.dot(s, dfc), axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "dots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def81254",
   "metadata": {},
   "source": [
    "The unique job titles that are **most similar** to `'deputy fire chief'` are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dots.index[dots == dots.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955afa7d",
   "metadata": {},
   "source": [
    "Note that they all share two words in common with `'deputy fire chief'`.\n",
    "\n",
    "**Note:** To truly use the dot product as a measure of similarity, we should **normalize** by the lengths of the word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb0ce4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words\n",
    "\n",
    "- The **bag of words** model represents texts (e.g. job titles, sentences, documents) as **vectors of word counts**.\n",
    "    - The \"counts\" matrices we have worked with so far were created using the bag of words model.\n",
    "    - The bag of words model defines a **vector space** in $\\mathbb{R}^{\\text{number of unique words}}$.\n",
    "- It is called \"bag of words\" because it doesn't consider **order**.\n",
    "\n",
    "<center><img src='imgs/bag-of-words.jpeg' width=45%></center>\n",
    "\n",
    "<center><a href=\"https://42f6861cgkip12ijm63i3orf-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/2020-07-bagofwords.jpg\">(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c67a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Interactive bag of words demo\n",
    "\n",
    "Check [this](https://svelte.dev/repl/98d158ef6fb842d09c66ed20b9a31e99?version=3.55.1) site out â€“ it automatically generates a bag of words matrix for you!\n",
    "\n",
    "<center><img src='imgs/bow-interactive.png' width=50%>(<a href=\"https://twitter.com/jdwlbr/status/1622704535511916544?s=20\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c05ead",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906fca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity and bag of words\n",
    "\n",
    "To measure the similarity between two word vectors, we compute their **normalized** dot product, also known as their **cosine similarity**.\n",
    "\n",
    "$$\\cos \\theta = \\boxed{\\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| | \\vec{b}|}}$$\n",
    "\n",
    "If $\\cos \\theta$ is large, the two word vectors are similar. **It is important to normalize by the lengths of the vectors**, otherwise texts with more words will have artificially high similarities with other texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32266bee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note:** Sometimes, you will see the **cosine distance** being used. It is the complement of cosine similarity:\n",
    "  \n",
    "  $$\\text{dist}(\\vec{a}, \\vec{b}) = 1 - \\cos \\theta$$\n",
    "  \n",
    "If $\\text{dist}(\\vec{a}, \\vec{b})$ is small, the two word vectors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef9257",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A recipe for computing similarities\n",
    "\n",
    "Given a set of documents, to find the **most similar** text to one _document_ $d$ in particular:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd1dfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use the bag of words model to create a counts matrix, in which:\n",
    "    - there is 1 row per document,\n",
    "    - there is 1 column per **unique** word that is used across documents, and\n",
    "    - the value in row `doc` and column `word` is the number of occurrences of `word` in `doc`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f069855",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Compute the cosine similarity between $d$'s row vector and all other documents' row vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584177e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The other document with the greatest cosine similarity is the most similar, under the bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81897bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Global warming ðŸŒŽ\n",
    "\n",
    "Consider the following three documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series([\n",
    "    'I really really want global peace',\n",
    "    'I must enjoy global warming',\n",
    "    'We must solve climate change'\n",
    "])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1a1e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent each document using the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(sentences.str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = sentences.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36677a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now find the cosine similarity between each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b30ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pair(s1, s2):\n",
    "    return np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f77468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the documentation of the .corr method to see how this works!\n",
    "counts_df.T.corr(sim_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee569a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue:** Bag of words only encodes the **words** that each document uses, not their **meanings**.\n",
    "- \"I really really want global peace\" and \"We must solve climate change\" have similar meanings, but have no shared words, and thus a low cosine similarity.\n",
    "- \"I really really want global peace\" and \"I must enjoy global warming\" have very different meanings, but a relatively high cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de88443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls of the bag of words model\n",
    "\n",
    "Remember, the key assumption underlying the bag of words model is that **two documents are similar if they share many words in common**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacec5d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model doesn't consider **order**.\n",
    "    - The job titles `'deputy fire chief'` and `'chief fire deputy'` are treated as the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7a0e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model doesn't consider the **meaning** of words.\n",
    "    - `'I love data science'` and `'I hate data science'` share 75% of their words, but have very different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0443e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model treats all words as being equally important.\n",
    "    - `'deputy'` and `'fire'` have the same importance, even though `'fire'` is probably more important in describing someone's job title.\n",
    "    - <span style=\"color:red\"><b>Let's address this point.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543520",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc3cdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The importance of words\n",
    "\n",
    "**Issue:** The bag of words model doesn't know which words are \"important\" in a document. Consider the following document:\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec183579",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do we determine which words are important?\n",
    "- The most common words (\"the\", \"has\") often **don't** have much meaning!\n",
    "- The very rare words are also less important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ad374",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Goal:** Find a way of quantifying the importance of a word in a document by **balancing the above two factors**, i.e. find the word that **best summarizes** a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d0ca0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency\n",
    "\n",
    "- The **term frequency** of a word (term) $t$ in a document $d$, denoted $\\text{tf}(t, d)$ is the proportion of words in document $d$ that are equal to $t$.\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705986d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** What is the term frequency of \"billy\" in the following document?\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d72cfd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** $\\frac{2}{13}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6edd0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: Words that occur often within a document are important to the document's meaning.\n",
    "    - If $\\text{tf}(t, d)$ is large, then word $t$ occurs often in $d$.\n",
    "    - If $\\text{tf}(t, d)$ is small, then word $t$ does not occur often $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276fb67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Issue: \"has\" also has a TF of $\\frac{2}{13}$, but it seems less important than \"billy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0cb0c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse document frequency\n",
    "\n",
    "- The **inverse document frequency** of a word $t$ in a set of documents $d_1, d_2, ...$ is\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813b844",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** What is the inverse document frequency of \"billy\" in the following three documents?\n",
    "    - \"my brother has a friend named **billy** who has an uncle named **billy**\"\n",
    "    - \"my favorite artist is named jilly boel\"\n",
    "    - \"why does he talk about someone named **billy** so often\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbcdd6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** $\\log \\left(\\frac{3}{2}\\right) \\approx 0.4055$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25153c15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: If a word appears in every document (like \"the\" or \"has\"), it is probably not a good summary of any one document.\n",
    "    - If $\\text{idf}(t)$ is large, then $t$ is rarely found in documents.\n",
    "    - If $\\text{idf}(t)$ is small, then $t$ is commonly found in documents.\n",
    "    - Think of $\\text{idf}(t)$ as the \"rarity factor\" of $t$ across documents â€“ the larger $\\text{idf}(t)$ is, the more rare $t$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce4c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$\n",
    "\n",
    "**Goal:** Quantify how well word $t$ **summarizes** document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc6634",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ is small, then $t$ doesn't occur very often in $d$, so $t$ can't be a good summary of $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18452d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{idf}(t)$ is small, then $t$ occurs often amongst all documents, and so it is not a good summary of any one document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569c752",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ and $\\text{idf}(t)$ are both large, then **$t$ occurs often in $d$ but rarely overall**. This makes $t$ **a good summary** of document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c7776",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency-inverse document frequency\n",
    "\n",
    "The **term frequency-inverse document frequency (TF-IDF)** of word $t$ in document $d$ is the product:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bd2c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tfidf}(t, d)$ is large, then $t$ is a good summary of $d$, because $t$ occurs often in $d$ but rarely across all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc456876",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- TF-IDF is a **heuristic** â€“ it has no probabilistic justification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a222c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To know if $\\text{tfidf}(t, d)$ is large for one particular word $t$, we need to compare it to $\\text{tfidf}(t_i, d)$, for several different words $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef231326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing TF-IDF\n",
    "\n",
    "**Question:** What is the TF-IDF of \"global\" in the second sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e7306",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = sentences.iloc[1].count('global') / len(sentences.iloc[1].split())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45953f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idf = np.log(len(sentences) / sentences.str.contains('global').sum())\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e1607",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** Is this big or small? Is \"global\" the **best** summary of the second sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af81a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all words in all documents\n",
    "\n",
    "On its own, the TF-IDF of a word in a document doesn't really tell us anything; we must compare it to TF-IDFs of other words in that same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212905a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405eab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(sentences.str.split().sum())\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict = {}\n",
    "\n",
    "for word in unique_words:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    tf = sentences.str.count(re_pat) / sentences.str.split().str.len()\n",
    "    idf = np.log(len(sentences) / sentences.str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] = tf * idf\n",
    "    \n",
    "tfidf = pd.DataFrame(tfidf_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00f89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39de10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting TF-IDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cadb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above DataFrame tells us that:\n",
    "- the TF-IDF of `'peace'` in the first sentence is 0.183102,\n",
    "- the TF-IDF of `'climate'` in the second sentence is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafb1ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that there are two ways that $\\text{tfidf}(t, d) = \\text{tf}(t, d) \\cdot \\text{idf}(t)$ can be 0:\n",
    "- If $t$ appears in every document, because then $\\text{idf}(t) = \\log (\\frac{\\text{# documents}}{\\text{# documents}}) = \\log(1) = 0$.\n",
    "- If $t$ does not appear in document $d$, because then $\\text{tf}(t, d) = \\frac{0}{\\text{len}(d)} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af48d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The word that **best summarizes** a document is the word with the highest TF-IDF for that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d8e94",
   "metadata": {},
   "source": [
    "Look closely at the rows of `tfidf` â€“ in documents 1 and 2, the max TF-IDF is not unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92963d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: State of the Union addresses ðŸŽ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980d913",
   "metadata": {},
   "source": [
    "### State of the Union addresses\n",
    "\n",
    "The 2023 State of the Union address was on February 7th, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40e0a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('gzcBTUvVp7M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec32713",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db49b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu = open('data/stateoftheunion1790-2023.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569714",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sotu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66057eca",
   "metadata": {},
   "source": [
    "The entire **corpus** (another word for \"set of documents\") is over 10 million characters long... let's not display it in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987af22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sotu[:16000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a60c4f",
   "metadata": {},
   "source": [
    "Each speech is separated by `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = sotu.split('\\n***\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723eec4",
   "metadata": {},
   "source": [
    "Note that each \"speech\" currently contains other information, like the name of the president and the date of the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f52e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(speeches[-1][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea89846",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's extract just the speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa932c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_struct(speech):\n",
    "    L = speech.strip().split('\\n', maxsplit=3)\n",
    "    L[3] = re.sub(r\"[^A-Za-z' ]\", ' ', L[3]).lower()\n",
    "    return dict(zip(['speech', 'president', 'date', 'contents'], L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5438e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(list(map(extract_struct, speeches)))\n",
    "speeches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1fade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the most important words in each speech\n",
    "\n",
    "Here, a \"document\" is a speech. We have 233 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bcc2d",
   "metadata": {},
   "source": [
    "A rough sketch of what we'll compute:\n",
    "\n",
    "```\n",
    "for each word t:\n",
    "    for each speech d:\n",
    "        compute tfidf(t, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d40a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(speeches_df['contents'].str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = unique_words.iloc[:500].index\n",
    "\n",
    "tfidf_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf = np.log(len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] =  tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidf_dict)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f34b9e",
   "metadata": {},
   "source": [
    "Note that the TF-IDFs of many common words are all 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15f5bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing speeches\n",
    "\n",
    "By using `idxmax`, we can find the word with the highest TF-IDF in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = tfidf.idxmax(axis=1)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad3811",
   "metadata": {},
   "source": [
    "What if we want to see the 5 words with the highest TF-IDFs, for each speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return list(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tfidf.apply(five_largest, axis=1)\n",
    "keywords_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762dd5e",
   "metadata": {},
   "source": [
    "Run the cell below to see every single row of `keywords_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf737b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    display(keywords_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a013b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: What if we remove the $\\log$ from $\\text{idf}(t)$?\n",
    "\n",
    "Let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf_nl = len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum()\n",
    "    tfidf_nl_dict[word] =  tf * idf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl = pd.DataFrame(tfidf_nl_dict)\n",
    "tfidf_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54838d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_nl = tfidf_nl.apply(five_largest, axis=1)\n",
    "keywords_nl_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords_nl\n",
    "], axis=1)\n",
    "keywords_nl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64da969",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The role of $\\log$ in $\\text{idf}(t)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$\n",
    "- Remember, for any positive input $x$, $\\log(x)$ is (much) smaller than $x$.\n",
    "- In $\\text{idf}(t)$, the $\\log$ \"dampens\" the impact of the ratio $\\frac{\\text{# documents}}{\\text{# documents with $t$}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d012ae6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very common, the ratio will be close to 1. The log of the ratio will be close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46db591",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1000 / 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1000 / 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66ce75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very rare, the ratio will be very large. However, for instance, a word being seen in **2 out of 50** documents is not very different than being seen in **2 out of 500** documents (it is very rare in both cases), and so $\\text{idf}(t)$ should be similar in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b376f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(500 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3643c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(500 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fb660",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- One way to turn documents, like `'deputy fire chief'`, into feature vectors, is to count the number of occurrences of each word in the document, ignoring order. This is done using the **bag of words** model.\n",
    "- To measure the similarity of two documents under the bag of words model, compute the cosine similarity of their two word vectors.\n",
    "- Term frequency-inverse document frequency (TF-IDF) is a statistic that tries to quantify how **important** a word (term) is to a document. It balances:\n",
    "    - **how often a word appears in a particular document**, $\\text{tf}(t, d)$, with\n",
    "    - **how often a word appears across documents**, $\\text{idf}(t)$.\n",
    "- For a given document, the word with the highest TF-IDF is thought to \"best summarize\" that document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dad56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Modeling and feature engineering."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
