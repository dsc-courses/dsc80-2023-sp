{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "# Used for plotting examples.\n",
    "def create_kde_plotly(df, group_col, group1, group2, vals_col, title=''):\n",
    "    fig = ff.create_distplot(\n",
    "        hist_data=[df.loc[df[group_col] == group1, vals_col], df.loc[df[group_col] == group2, vals_col]],\n",
    "        group_labels=[group1, group2],\n",
    "        show_rug=False, show_hist=False,\n",
    "        colors=['#ef553b', '#636efb'],\n",
    "    )\n",
    "    return fig.update_layout(title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 12 â€“ Identifying Missingness Mechanisms\n",
    "\n",
    "## DSC 80, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadf287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 4 is due **tonight at 11:59PM**.\n",
    "    - See [this post on Ed](https://edstem.org/us/courses/32057/discussion/2490014) for clarifications.\n",
    "- Project 2 is due on **Thursday, February 9th at 11:59PM**.\n",
    "- The Grade Report on Gradescope now contains scores and slip days through Lab 3.\n",
    "- **Remember to run `conda activate dsc80` before working on assignments!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Review and discussion: missingness mechanisms.\n",
    "- Deciding between MCAR and MAR using permutation tests.\n",
    "- A new test statistic for permutation tests: the Kolmogorov-Smirnov statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1321c1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missingness mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d636748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flowchart\n",
    "\n",
    "A good strategy is to assess missingness in the following order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00879c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing by design (MD)</b></center>\n",
    "<center><i>Can I determine the missing value exactly by looking at the other columns?</i> ðŸ¤”</center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eebc90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Not missing at random (NMAR)</b></center>\n",
    "<center><i>Is there a good reason why the missingness depends on the values themselves?</i> ðŸ¤”</center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f82f0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing at random (MAR)</b></center>\n",
    "<center><i>Do other columns tell me anything about the likelihood that a value is missing? </i>ðŸ¤”</center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225bcaf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing completely at random (MCAR)</b></center>\n",
    "<center><i>The missingness must not depend on other columns or the values themselves. </i>ðŸ˜„</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c83846",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "In each of the following examples, decide whether the missing data are likely to be MD, NMAR, MAR, or MCAR:\n",
    "\n",
    "* A table for a medical study has columns for `'gender'` and `'age'`. **`'age'` has missing values**.\n",
    "* Measurements from the Hubble Space Telescope are **dropped during transmission**.\n",
    "* A table has a single column, `'self-reported education level'`, **which contains missing values**.\n",
    "* A table of grades contains three columns, `'Version 1'`, `'Version 2'`, and `'Version 3'`. **$\\frac{2}{3}$ of the entries in the table are `NaN`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878293f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do we care again?\n",
    "\n",
    "- If a dataset contains missing values, it is likely not an accurate picture of the data generating process.\n",
    "- By identifying missingness mechanisms, we can best **fill in** missing values, to gain a better understanding of the DGP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd64c14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formal definitions\n",
    "\n",
    "We won't spend much time on these in lecture, but you may find them helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6809620",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: MCAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "Data is **missing completely at random** (MCAR) if \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi) = \\text{P}(\\text{data is present} \\: | \\: \\psi)$$\n",
    "\n",
    "That is, adding information about the dataset doesn't change the likelihood data is missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf2151",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: MAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "Data is **missing at random** (MCAR) if \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi) = \\text{P}(\\text{data is present} \\: | \\: Y_{obs},  \\psi)$$\n",
    "\n",
    "That is, MAR data is **actually MCAR**, **conditional** on $Y_{obs}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2646f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: NMAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "\n",
    "Data is **not missing at random** (NMAR) if  \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi)$$\n",
    "\n",
    "cannot be simplified. That is, in NMAR data, **missingness is dependent on the missing value** itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01815d59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing missingness through data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c90aaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing missingness through data\n",
    "\n",
    "- Suppose I believe that the missingness mechanism of a column is NMAR, MAR, or MCAR.\n",
    "    - I've ruled out missing by design (a good first step).\n",
    "- Can I check whether this is true, by looking at the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03bc07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing NMAR\n",
    "\n",
    "- We can't determine if data is NMAR just by looking at the data, as whether or not data is NMAR depends on the **unobserved data**.\n",
    "- To establish if data is NMAR, we must:\n",
    "    - **reason about the data generating process**, or\n",
    "    - collect more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0312b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** Consider a dataset of survey data of students' self-reported happiness. The data contains PIDs and happiness scores; nothing else. Some happiness scores are missing. **Are happiness scores likely NMAR?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2560c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing MAR\n",
    "\n",
    "- Data are MAR if the missingness only depends on **observed** data.\n",
    "- After reasoning about the data generating process, if you establish that data is not NMAR, then it must be either MAR or MCAR.\n",
    "- The more columns we have in our dataset, the \"weaker the NMAR effect\" is.\n",
    "    - Adding more columns -> controlling for more variables -> moving from NMAR to MAR.\n",
    "    - **Example:** With no other columns, income in a census is NMAR. But once we look at location, education, and occupation, incomes are closer to being MAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd364b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deciding between MCAR and MAR\n",
    "\n",
    "- For data to be MCAR, the chance that values are missing should not depend on any other column or the values themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79812fa1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: Consider a dataset of phones, in which we store the screen size and price of each phone. **Some prices are missing.**\n",
    "\n",
    "| Phone | Screen Size | Price |\n",
    "| --- | --- | --- |\n",
    "| iPhone 14 | 6.06 | 999 |\n",
    "| Galaxy Z Fold 4 | 7.6 | NaN |\n",
    "| OnePlus 9 Pro | 6.7 | 799 |\n",
    "| iPhone 13 Pro Max | 6.68 | NaN |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56961812",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If prices are MCAR, then **the distribution of screen size should be the same** for:\n",
    "    - phones whose prices are missing, and \n",
    "    - phones whose prices aren't missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677691d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We can use a permutation test to decide between MAR and MCAR!** We are asking the question, did these two samples come from the same underlying distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb93a09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deciding between MCAR and MAR\n",
    "\n",
    "Suppose you have a DataFrame with columns named $\\text{col}_1$, $\\text{col}_2$, ..., $\\text{col}_k$, and want to test whether values in $\\text{col}_X$ are MCAR. To test whether $\\text{col}_X$'s missingness is independent of all other columns in the DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a85d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For $i = 1, 2, ..., k$, where $i \\neq X$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be428db7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Look at the distribution of $\\text{col}_i$ when $\\text{col}_X$ is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818ee27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Look at the distribution of $\\text{col}_i$ when $\\text{col}_X$ is not missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783d1af",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Check if these two distributions are the same. (What do we mean by \"the same\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cd0db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If so, then $\\text{col}_X$'s missingness doesn't depend on $\\text{col}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7681d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If not, then $\\text{col}_X$ is MAR dependent on $\\text{col}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc1285",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If all pairs of distribution were the same, then $\\text{col}_X$ is MCAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20bd5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Heights\n",
    "\n",
    "- Let's load in Galton's dataset containing the heights of adult children and their parents (which you may have seen in DSC 10).\n",
    "- The dataset does not contain any missing values â€“ we will **artifically introduce missing values** such that the values are MCAR, for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a2bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heights = pd.read_csv('data/midparent.csv')\n",
    "heights = heights.rename(columns={'childHeight': 'child'})\n",
    "heights = heights[['father', 'mother', 'gender', 'child']]\n",
    "heights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d3802",
   "metadata": {},
   "source": [
    "Proof that there aren't currently any missing values in `heights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb94046",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f470d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have three numerical columns â€“ `'father'`, `'mother'`, and `'child'`. Let's visualize them simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(heights.drop(columns=['gender']))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaab080",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MCAR data\n",
    "\n",
    "- We will make `'child'` MCAR by taking a random subset of `heights` and setting the corresponding `'child'` heights to `np.NaN`.\n",
    "- This is equivalent to flipping a (biased) coin for each row. \n",
    "    - If heads, we delete the `'child'` height.\n",
    "- **You will not do this in practice!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "heights_mcar = heights.copy()\n",
    "idx = heights_mcar.sample(frac=0.3).index\n",
    "heights_mcar.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fec198",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f4943",
   "metadata": {},
   "source": [
    "Aside: Why is the value for `'child'` in the above Series not exactly 0.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3096b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verifying that child heights are MCAR in `heights_mcar`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d265f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each row of `heights_mcar` belongs to one of two **groups**:\n",
    "    - Group 1: `'child'` is missing.\n",
    "    - Group 2: `'child'` is not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar['child_missing'] = heights_mcar['child'].isna()\n",
    "heights_mcar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f46bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need to look at the distributions of every other column â€“ `'gender'`, `'mother'`, and `'father'` â€“ separately for these two groups, and check to see if they are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903253af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mcar\n",
    "    .assign(child_missing=heights_mcar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "# Added just to make the resulting pivot table easier to read.\n",
    "gender_dist.columns = ['child_missing = False', 'child_missing = True']\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed2244",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that here, each column is a separate distribution that adds to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556eb160",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The two columns look similar, which is evidence that `'child'`'s missingness does not depend on `'gender'`.\n",
    "    - Knowing that the child is `'female'` doesn't make it any more or less likely that their height is missing than knowing if the child is `'male'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69137c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`\n",
    "\n",
    "- In the previous slide, we saw that the distribution of `'gender'` is similar whether or not `'child'` is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400e34a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To make precise what we mean by \"similar\", we can run a permutation test. We are comparing two distributions:\n",
    "    1. The distribution of `'gender'` when `'child'` is missing.\n",
    "    2. The distribution of `'gender'` when `'child'` is not missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37405e72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What test statistic do we use to compare categorical distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e7788",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', title='Gender by Missingness of Child Height', barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34398a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To measure the \"distance\" between two categorical distributions, we use the **total variation distance**.\n",
    "\n",
    "Note that  with only two categories, the TVD is the same as the absolute difference in proportions for either category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12c13e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation\n",
    "\n",
    "The code to run our simulation largely looks the same as in previous permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57194779",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = heights_mcar.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling genders. \n",
    "    # Note that we are assigning back to the same DataFrame for performance reasons; \n",
    "    # see https://dsc80.com/resources/lectures/lec11/lec11-fast-permutation-tests.html.\n",
    "    shuffled['gender'] = np.random.permutation(shuffled['gender'])\n",
    "    \n",
    "    # Computing and storing the TVD.\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    "        .apply(lambda x: x / x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952a343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_tvd = gender_dist.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae18299",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the TVD')\n",
    "fig.add_vline(x=observed_tvd, line_color='red')\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=2.3 * observed_tvd, showarrow=False, y=0.16)\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce201999",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(tvds) >= observed_tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af6c73",
   "metadata": {},
   "source": [
    "- We fail to reject the null.\n",
    "- Recall, the null stated that the distribution of `'gender'` when `'child'` is missing is the same as the distribution of `'gender'` when `'child'` is not missing.\n",
    "- Hence, we conclude that the missingness in the `'child'` column is not dependent on `'gender'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222acc46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5a00e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We again must compare two distributions:\n",
    "    1. The distribution of `'father'` when `'child'` is missing.\n",
    "    2. The distribution of `'father'` when `'child'` is not missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb48ea7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the distributions are similar, we conclude that the missingness of `'child'` is not dependent on the height of the `'father'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edeca0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can again use a permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78287427",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(heights_mcar, x='father', color='child_missing', histnorm='probability', marginal='box',\n",
    "             title=\"Father's Height by Missingness of Child Height\", barmode='overlay', opacity=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341fe2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can visualize numerical distributions with histograms, or with **kernel density estimates**. (See the definition of `create_kde_plotly` at the top of the notebook if you're curious as to how these are created.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d44c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_kde_plotly(heights_mcar, 'child_missing', True, False, 'father', \n",
    "                  \"Father's Height by Missingness of Child Height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4938cd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concluding that `'child'` is MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6422d7f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need to run three permutation tests â€“ one for each column in `heights_mcar` other than `'child'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a6cf8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For every other column, if we **fail to reject the null** that the distribution of the column when `'child'` is missing is the same as the distribution of the column when `'child'` is not missing, then we can conclude `'child'` is MCAR.\n",
    "    - In such a case, its missingness is not tied to any other columns.\n",
    "    - For instance, children with shorter fathers are not any more likely to have missing heights than children with taller fathers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086a8c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MAR data\n",
    "\n",
    "Now, we will make `'child'` heights MAR by deleting `'child'` heights according to a random procedure that **depends on other columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98aa834",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "def make_missing(r):\n",
    "    rand = np.random.uniform() # Random real number between 0 and 1.\n",
    "    if r['father'] > 72 and rand < 0.5:\n",
    "        return np.NaN\n",
    "    elif r['gender'] == 'female' and rand < 0.3:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return r['child']\n",
    "    \n",
    "heights_mar = heights.copy()\n",
    "heights_mar['child'] = heights_mar.apply(make_missing, axis=1)\n",
    "heights_mar['child_missing'] = heights_mar['child'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dc107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`, again\n",
    "\n",
    "This time, the distribution of `'gender'` in the two groups is very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232969dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mar\n",
    "    .assign(child_missing=heights_mar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "# Added just to make the resulting pivot table easier to read.\n",
    "gender_dist.columns = ['child_missing = False', 'child_missing = True']\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc305106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', title='Gender by Missingness of Child Height', barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223024ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: If we take the average of the non-null `'child'` heights in the dataset with missing values, will it be less than or greater than the average `'child'` height in the full dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922c255",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**:\n",
    "    - `'child'` heights tend to be missing much more frequently when the child is `'female'`.\n",
    "    - Adult females tend to be shorter than adult males on average.\n",
    "    - Thus, the average `'child'` height in the dataset with missing values will be **greater than** the average `'child'` height in the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f423df8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# When child heights are MAR:\n",
    "heights_mar['child'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d77786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When child heights are not missing:\n",
    "heights['child'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When child heights are MCAR:\n",
    "heights_mcar['child'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33699c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdf543",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_kde_plotly(heights_mar, 'child_missing', True, False, 'father', \n",
    "                  \"Father's Height by Missingness of Child Height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358c0b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above two distributions look quite different.\n",
    "    - This is because we artificially created missingness in the dataset in a way that depended on `'father'` and `'gender'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4391724",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, their difference in means is small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc36c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar.groupby('child_missing')['father'].mean().diff().iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50521ade",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we ran a permutation test with the difference in means as our test statistic, we would fail to reject the null.\n",
    "    - **Using just the difference in means, it is hard to tell these two distributions apart.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e21dcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Kolmogorov-Smirnov test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b01d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Permutation tests\n",
    "\n",
    "- Permutation tests help decide whether **two samples look like they were drawn from the same population distribution**.\n",
    "- In a permutation test, we simulate data under the null by **shuffling** either group labels or numerical features.\n",
    "    - In effect, this **randomly assigns individuals to groups**.\n",
    "- If the two distributions are **quantitative (numerical)**, we use as our test statistic the **difference in group means or medians**.\n",
    "- If the two distributions are **qualitative (categorical)**, we use as our test statistic the **total variation distance (TVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee559907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means\n",
    "\n",
    "The difference in means works well in some cases. Let's look at one such case.\n",
    "\n",
    "Below, we artificially generate two numerical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e01b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "distr1 = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(3, 1, size=N//2))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5077161",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6f7e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "- So far, we have used the difference in means as our test statistic in quantitative permutation tests.\n",
    "- We've concluded that **two distributions were likely different if their means were different**.\n",
    "- Can you think of two **different** distributions that have the same mean? ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad61ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different distributions with the same mean\n",
    "\n",
    "Let's generate two distributions that look very different but have the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a76426",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "a = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "b = pd.Series(np.random.normal(4, 1, size=N//2))\n",
    "distr1 = pd.concat([a,b], ignore_index=True)\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(distr1.mean(), distr1.std(), size=N))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902414f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ce709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, if we use the difference in means as our test statistic in a permutation test, we will fail to reject the null that the two distributions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f99b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "diff_means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the values, while keeping the group labels in place.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the absolute difference in means.\n",
    "    diff_mean = shuffled.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "    diff_means.append(diff_mean)\n",
    "    \n",
    "diff_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07361789",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "observed_diff = data.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "fig = px.histogram(pd.DataFrame(diff_means), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the Absolute Difference in Means')\n",
    "fig.add_vline(x=observed_diff, line_color='red')\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed Absolute Difference in Means = {round(observed_diff, 2)}</span>',\n",
    "                   x=1.45 * observed_diff, showarrow=False, y=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The computed p-value is fairly large.\n",
    "np.mean(np.array(diff_means) >= observed_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd283870",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Telling quantitative distributions apart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4e0d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The difference in means only works as a test statistic in permutation tests **if the two distributions have similar shapes**.\n",
    "    - It tests to see if one is a shifted version of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3754f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a better test statistic to differentiate between quantitative distributions with different shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bd3fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In other words, we need a **distance** metric between quantitative distributions.\n",
    "    - The TVD is a distance metric between categorical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c37a95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Kolmogorov-Smirnov test statistic\n",
    "\n",
    "- The K-S test statistic measures the similarity between two distributions.\n",
    "- It is defined in terms of the **cumulative distribution function (CDF)** of a given distribution.\n",
    "    - If $f(x)$ is a distribution, then the CDF $F(x)$ is the proportion of values in distribution $f$ that are less than or equal to $x$.\n",
    "- The K-S statistic is roughly defined as the **largest difference between two CDFs**.\n",
    "<center><img src=./imgs/KS2_Example.png width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587e2a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: cumulative distribution functions\n",
    "\n",
    "Let's look at the CDFs of our two synthetic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6bfa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Think about what this function is doing!\n",
    "def create_cdf(group):\n",
    "    return data.loc[data['group'] == group, 'data'].value_counts(normalize=True).sort_index().cumsum()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=create_cdf('A').index, y=create_cdf('A'), name='CDF of A')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=create_cdf('B').index, y=create_cdf('B'), name='CDF of B')\n",
    ")\n",
    "\n",
    "fig.update_layout(title='CDFs of A and B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc18b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The K-S statistic in Python\n",
    "\n",
    "Fortunately, **we don't need to calculate the K-S statistic ourselves**! Python can do it for us (and you can use this pre-built version in all assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb045882",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86095baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ks = ks_2samp(data.loc[data['group'] == 'A', 'data'], data.loc[data['group'] == 'B', 'data']).statistic\n",
    "observed_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d59ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We don't know if this number is big or small. We need to run a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "ks_stats = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the data.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the K-S statistic.\n",
    "    groups = shuffled.groupby('group')['data']\n",
    "    ks_stat = ks_2samp(groups.get_group('A'), groups.get_group('B')).statistic\n",
    "    ks_stats.append(ks_stat)\n",
    "    \n",
    "ks_stats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fd255",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(ks_stats), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the K-S Statistic')\n",
    "fig.add_vline(x=observed_ks, line_color='red')\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed KS = {round(observed_ks, 2)}</span>',\n",
    "                   x=0.85 * observed_ks, showarrow=False, y=0.16)\n",
    "\n",
    "fig.update_layout(xaxis_range=[0, 0.2])\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(ks_stats) >= observed_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15934f5",
   "metadata": {},
   "source": [
    "We were able to differentiate between the two distributions using the K-S test statistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49301fbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `ks_2samp`\n",
    "\n",
    "* `scipy.stats.ks_2samp` actually returns **both** the statistic **and** a p-value.\n",
    "* The p-value is calculated using the permutation test we just performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7360aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(data.loc[data['group'] == 'A', 'data'], data.loc[data['group'] == 'B', 'data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f3766",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f1a84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- We can use permutation tests to verify if a column is MAR vs. MCAR.\n",
    "    - Create two groups: one where values in a column are missing, and another where values in a column aren't missing.\n",
    "    - To test the missingness of column X:\n",
    "        - For every other column, test the null hypothesis \"the distribution of (other column) is the same when column X is missing and when column X is not missing.\"\n",
    "        - If you fail to reject the null, then column X's missingness does not depend on (other column).\n",
    "        - If you reject the null, then column X is MAR dependent on (other column).\n",
    "        - If you fail to reject the null for all other columns, then column X is MCAR!\n",
    "- To compare two distributions in a permutation test, the choice of test statistic depends on the type and shape of the distributions:\n",
    "    - If the two distributions are **qualitative (categorical)**, use the **total variation distance (TVD)**.\n",
    "    - If the two distributions are **quantitative (numerical)** and look like shifted versions of the same basic shape, use the **difference in group means or medians**.\n",
    "    - If the two distributions are **quantitative (numerical)** and are centered in the same location but have different shapes, use the **Kolmogorov-Smirnov statistic**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
