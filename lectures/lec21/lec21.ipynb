{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904f660",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "TEMPLATE = 'seaborn'\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 21 ‚Äì Feature Engineering\n",
    "\n",
    "## DSC 80, Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadf287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üì£ Announcements\n",
    "\n",
    "- Project 4 is due on **Thursday, March 9th at 11:59PM**.\n",
    "- Lab 8 (modeling) is due on **Monday, March 6th at 11:59PM**.\n",
    "- RSVP to the Senior Capstone Showcase on March 15th at [**hdsishowcase.com**](https://hdsishowcase.com).\n",
    "    - There is no live lecture for DSC 80 on the day of the showcase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Case study: Restaurant tips üßë‚Äçüç≥.\n",
    "    - Other methods for evaluating regression models.\n",
    "- Feature engineering.\n",
    "    - One hot encoding.\n",
    "    - Encoding categorical features, both nominal and ordinal.\n",
    "    - Quantitative scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Case study: Restaurant tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebf5eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly (and seaborn)!\n",
    "# We shuffle here so that the head of the DataFrame contains rows where smoker is Yes and smoker is No,\n",
    "# purely for illustration purposes (it doesn't change any of the math).\n",
    "np.random.seed(1)\n",
    "tips = px.data.tips().sample(frac=1).reset_index(drop=True)\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ef9bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #1: Constant\n",
    "\n",
    "Let's suppose we choose squared loss, meaning that $h^* = \\text{mean}(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tip = tips['tip'].mean()\n",
    "mean_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3add1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Unfortunately, the code to visualize a scatter plot and a line\n",
    "# in plotly is not all that concise.\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tips['total_bill'], \n",
    "    y=tips['tip'], \n",
    "    mode='markers',\n",
    "    name='Original Data')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 60],\n",
    "    y=[mean_tip, mean_tip],\n",
    "    mode='lines',\n",
    "    name='Constant Prediction (Mean)'\n",
    "))\n",
    "\n",
    "fig.update_layout(showlegend=True, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip',\n",
    "                  template=TEMPLATE)\n",
    "fig.update_xaxes(range=[0, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4d30b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's compute the RMSE of our constant tip's predictions, and store it in a dictionary that we can refer to later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34633352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7060d61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #2: Simple linear regression using total bill\n",
    "\n",
    "We can fit a **simple linear model** to predict tips as a function of total bill:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0171c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 60],\n",
    "    y=model.predict([[0], [60]]),\n",
    "    mode='lines',\n",
    "    name='Linear: Total Bill Only'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d84da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = model.predict(tips[['total_bill']])\n",
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319bc0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The RMSE of our simple linear model is **lower** than that of our constant model, which means it does a **better job** at modeling the training data than our constant model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037400cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #3: Multiple linear regression using total bill and table size\n",
    "\n",
    "Let's try using another feature ‚Äì table size. Such a model would predict tips using:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce651f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e18991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.predict([[25, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6967c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does this model _look_ like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9f722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plane of best fit ‚úàÔ∏è\n",
    "\n",
    "Here, we must draw a 3D scatter plot and plane, with one axis for total bill, one axis for table size, and one axis for tip. The code below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z = model_two.intercept_ + model_two.coef_[0] * XX + model_two.coef_[1] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z, colorscale='Oranges')\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=tips['total_bill'], \n",
    "                           y=tips['size'], \n",
    "                           z=tips['tip'], mode='markers', marker = {'color': '#656DF1'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'),\n",
    "  title='Tip vs. Total Bill and Table Size',\n",
    "    width=1000, height=800,\n",
    "    template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ffbb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing models, again \n",
    "\n",
    "How does our two-feature linear model stack up to our single feature linear model and our constant model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f85ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The RMSE of our two-feature model is the lowest of the three models we've looked at so far, but not by much. We didn't **gain** much by adding table size to our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49078a69",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's also not clear whether table sizes are practically useful in predicting tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ae07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.score` method of a `LinearRegression` object\n",
    "\n",
    "Model objects in `sklearn` that have already been fit have a `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bd253",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That doesn't look like the RMSE... what is it? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b29366",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248c0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $R^2$, or the **coefficient of determination**, is a measure of the **quality of a linear fit**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c217f49",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are a few equivalent ways of computing it, assuming your model **is linear and has an intercept term**:\n",
    "\n",
    "$$R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$$\n",
    "\n",
    "$$R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc82211",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Interpretation: $R^2$ is the **proportion of variance in $y$ that the linear model explains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f3fa8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the simple linear regression case, it is the square of the correlation coefficient, $r$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20b764",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea:** $R^2$ ranges from 0 to 1. **The closer it is to 1, the better the linear fit is.**\n",
    "    - $R^2$ has no units of measurement, unlike RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10277e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "`all_preds` contains `model_two`'s predicted `'tip'` for every row in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82052b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68507b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_preds = model_two.predict(tips[['total_bill', 'size']])\n",
    "all_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57861383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(all_preds) / np.var(tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a91f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$, the same correlation coefficient you saw in DSC 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.corrcoef(all_preds, tips['tip'])) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fe309",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 3:** `LinearRegression.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ffe7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f084",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dd70c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LinearRegression` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(X, y)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(X_new)`| Uses regression line to make predictions|\n",
    "|Evaluate the model| `lr.score(X, y)` | Calculates the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_`, `lr.intercept_` | Accesses the regression coefficients and intercept|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153988b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, in our journey to predict `'tip'`, we've only used the existing numerical features in our dataset, `'total_bill'` and `'size'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd2527",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There's a lot of information in tips that we didn't use ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'`, for example. We can't use these features in their current form, because they're non-numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88ea5c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **How do we use categorical features in a regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b777e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc7b5c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6ad0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A feature function $\\phi$ (phi, pronounced \"fea\") is a mapping from raw data to $d$-dimensional space, i.e. $\\phi: \\text{raw data} \\rightarrow \\mathbb{R}^d$.\n",
    "    - If two observations $x_i$ and $x_j$ are \"similar\" in the raw data space, then $\\phi(x_i)$ and $\\phi(x_j)$ should also be \"similar.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f714c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- A \"good\" choice of features depends on many factors:\n",
    "    - The kind of data (quantitative, ordinal, nominal).\n",
    "    - The relationship(s) and association(s) being modeled.\n",
    "    - The model type (e.g. linear models, decision tree models, neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e155a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a31e16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is a transformation that turns a categorical feature into several binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c2a48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose column `'col'` has $N$ unique values, $A_1$, $A_2$, ..., $A_N$. For each unique value $A_i$, we define the following **feature function**:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c3d75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that 1 means \"yes\" and 0 means \"no\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a5c94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is also called \"dummy encoding\", and $\\phi(x)$ may also be referred to as an \"indicator variable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc658794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding `'smoker'`\n",
    "\n",
    "For each unique value of `'smoker'` in our dataset, we must create a column for just that `'smoker'`. (Remember, `'smoker'` is `'Yes'` when the table was in the smoking section of the restaurant and `'No'` otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c21be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tips['smoker'] == 'Yes').astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in tips['smoker'].unique():\n",
    "    tips[f'smoker == {val}'] = (tips['smoker'] == val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ccee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #4: Multiple linear regression using total bill, table size, and smoker status\n",
    "\n",
    "Now that we've converted `'smoker'` to a numerical variable, we can use it as input in a regression model. Here's the model we'll try to fit:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size} + w_3 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872778a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Subtlety**: There's no need to use _both_ `'smoker == No'` and `'smoker == Yes'`. If we know the value of one, we already know the value of the other. We can use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three = LinearRegression()\n",
    "model_three.fit(tips[['total_bill', 'size', 'smoker == Yes']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c29f19",
   "metadata": {},
   "source": [
    "The following cell gives us our $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08d4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_three.intercept_, model_three.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685cb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, our trained linear model to predict tips given total bills, table sizes, and smoker status (yes or no) is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a31b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing Model #4\n",
    "\n",
    "Our new fit model is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca544c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To visualize our data and linear model, we'd need 4 dimensions:\n",
    "- One for total bill\n",
    "- One for table size\n",
    "- One for `'smoker == Yes'`.\n",
    "- One for tip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85ebee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Humans can't visualize in 4D, but there may be a solution. We know that `'smoker == Yes'` only has two possible values, 1 or 0, so let's look at those cases separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f67d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Case 1**: `'smoker == Yes'` is 1, meaning that the table **was** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 1 \\\\ &= 0.626 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac8dde",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Case 2**: `'smoker == Yes'` is 0, meaning that the table **was not** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 0 \\\\ &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e760d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: These are two parallel planes in 3D, with different $z$-intercepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3f2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the two planes are very close to one another ‚Äì you'll have to zoom in to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z_0 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 0\n",
    "Z_1 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 1\n",
    "plane_0 = go.Surface(x=XX, y=YY, z=Z_0, colorscale='Greens')\n",
    "plane_1 = go.Surface(x=XX, y=YY, z=Z_1, colorscale='Purples')\n",
    "\n",
    "fig = go.Figure(data=[plane_0, plane_1])\n",
    "\n",
    "tips_0 = tips[tips['smoker'] == 'No']\n",
    "tips_1 = tips[tips['smoker'] == 'Yes']\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_0['total_bill'], \n",
    "                           y=tips_0['size'], \n",
    "                           z=tips_0['tip'], mode='markers', marker = {'color': 'green'}))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_1['total_bill'], \n",
    "                           y=tips_1['size'], \n",
    "                           z=tips_1['tip'], mode='markers', marker = {'color': 'purple'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'),\n",
    "  title='Tip vs. Total Bill and Table Size (Green = Non-Smoking Section, Purple = Smoking Section)',\n",
    "    width=1000, height=800,\n",
    "    showlegend=False,\n",
    "    template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2302b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to visualize in 2D, we need to pick a single feature to place on the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45adfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], \n",
    "                         mode='markers', name='Original Data'))\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]), \n",
    "                         mode='markers', name='Predicted Tips using Total Bill, Table Size, and Smoker Status'))\n",
    "\n",
    "fig.update_layout(showlegend=True, template=TEMPLATE, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6c67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Despite being a linear model, why **doesn't** this model **look** like a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36750de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Model #4 to earlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['three features'] = rmse(tips['tip'], \n",
    "                                   model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]))\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding `'smoker == Yes'` decreased the training RMSE of our model, but **barely**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cdc3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201375c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've one hot encoded `'smoker'`, but it required a `for`-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1941a3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is there an easy way to one hot encode all four categorical columns ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'` ‚Äì all at once, without using a `for`-loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fbade",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Yes, using `sklearn.preprocessing`'s `OneHotEncoder`. More on this in the next lecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7705f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Predicting ratings ‚≠êÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d7777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting ratings ‚≠êÔ∏è\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9761d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to build a multiple regression model that predicts `'RATING'` using the above features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa699f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why can't we build a model right away? What must we do so that we can build a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd5cf0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some issues: Missing values, emojis and strings instead of numbers, unrelated columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94368ca4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uninformative features\n",
    "\n",
    "- `'UID'` was likely used to join the user information (e.g., `'AGE'` and `'STATE'`) with some `reviews` dataset.\n",
    "- Even though `'UID'`s are stored as **numbers**, the numerical value of a user's `'UID'` won't help us predict their `'RATING'`.\n",
    "- If we include the `'UID'` feature, our model will find whatever patterns it can between `'UID'`s and `'RATING'`s in the training (observed data).\n",
    "    - This will lead to a lower training RMSE.\n",
    "- However, since there is truly no relationship between `'UID'` and `'RATING'`, this will lead to **worse** model performance on unseen data (bad).\n",
    "- **Transformation:** drop `'UID'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c96d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. When the features **do not contain information** associated with the prediction task. \n",
    "2. When the feature is **not available at prediction time.**  \n",
    "- The goal of building a model to predict `'RATING'`s is so that we can **predict `'RATING'`s for users who haven't actually made a `'RATING'`s yet**.\n",
    "- As such, our model should only depend on features that we would know before the user makes their `'RATING'`.\n",
    "- For instance, if users only enter `'REVIEW'`s after entering `'RATING'`s, we shouldn't use `'REVIEW'`s as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574cfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding ordinal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'RATING'` column, an ordinal variable, as a quantitative variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c558ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Transformation:** Replace \"number of &#10025;\" with \"number\".\n",
    "    - This is an **ordinal encoding**, a transformation that maps ordinal values to the positive integers in a way that preserves order.\n",
    "    - Example: (freshman, sophomore, junior, senior) -> (0, 1, 2, 3).\n",
    "    - **Important:** This transformation preserves \"distances\" between ratings.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "order_values = ['‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©‚ú©']\n",
    "ordinal_enc = {y:x + 1 for (x, y) in enumerate(order_values)}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame().assign(RATING=['‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©‚ú©'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebe95e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding nominal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'STATE'` column, a nominal variable, as a quantitative variable? In other words, how do we turn `'STATE'`s into meaningful numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31060132",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Why can't we use an ordinal encoding, e.g. NY -> 0, WA -> 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95ff6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: There is no inherent ordering to states, e.g. WA is not inherently \"more\" of anything than NY."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5c9a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We've already seen the correct strategy**: one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6cb7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Horsepower üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31c6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following dataset, built into the `seaborn` plotting library, contains various information about (older) cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74629562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg').dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b32614",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We really do mean old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['model_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30a172",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's investigate the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3bf75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between `'horsepower'` and `'mpg'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5268d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: To create a simple scatter plot, all you need is\n",
    "# px.scatter(mpg, x='horsepower', y='mpg').\n",
    "# We've used the more complicated go.Scatter approach here so that we can add\n",
    "# other lines on top.\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=mpg['horsepower'], \n",
    "    y=mpg['mpg'], \n",
    "    mode='markers',\n",
    "    name='Original Data')\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=True, title='MPG vs. Horsepower',\n",
    "                  xaxis_title='Horsepower', yaxis_title='MPG',\n",
    "                  template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887d19e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It appears that there is a negative association between `'horsepower'` and `'mpg'`, though it's not quite linear. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d18b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try and fit a simple linear model that uses `'horsepower'` to predict `'mpg'` and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08a100",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `'horsepower'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model = LinearRegression()\n",
    "car_model.fit(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Scatter(\n",
    "    x=[25, 225],\n",
    "    y=car_model.predict([[25], [225]]),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using Horsepower'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our regression line doesn't _quite_ capture the curvature in the relationship between `'horsepower'` and `'mpg'`.\n",
    "\n",
    "Let's compute the $R^2$ of `car_model` on our training data, for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model.score(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3ec7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations\n",
    "\n",
    "The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which transformations to apply to data in order to **linearize** it.\n",
    "\n",
    "<center><img src=\"imgs/bulge.png\" width=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164a12",
   "metadata": {},
   "source": [
    "The bottom-left quadrant appears to match the shape of the scatter plot between `'horsepower'` and `'mpg'` the best ‚Äì let's try taking the `log` of `'horsepower'` ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['log hp'] = np.log(mpg['horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b77c02",
   "metadata": {},
   "source": [
    "What does our data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = go.Figure()\n",
    "\n",
    "log_fig.add_trace(go.Scatter(\n",
    "    x=mpg['log hp'], \n",
    "    y=mpg['mpg'], \n",
    "    mode='markers',\n",
    "    name='Original Data')\n",
    ")\n",
    "\n",
    "log_fig.update_layout(showlegend=True, title='MPG vs. log(Horsepower)',\n",
    "                  xaxis_title='log(Horsepower)', yaxis_title='MPG',\n",
    "                  template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686dfcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `log('horsepower')`\n",
    "\n",
    "Let's fit another linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12526744",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log = LinearRegression()\n",
    "car_model_log.fit(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e490f0",
   "metadata": {},
   "source": [
    "What do our predictions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c43675",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig.add_trace(go.Scatter(\n",
    "    x=[3.7, 5.5],\n",
    "    y=car_model_log.predict([[3.7], [5.5]]),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using log(Horsepower)'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fe456",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fit looks a bit better! How about the $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.score(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1fa5",
   "metadata": {},
   "source": [
    "Also a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724aa37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do our predictions look like on the original, non-transformed scatter plot? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=mpg['horsepower'], \n",
    "        y=car_model_log.intercept_ + car_model_log.coef_[0] * np.log(mpg['horsepower']),  \n",
    "        mode='markers', name='Predicted MPG using log(Horsepower)', marker_color='red'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93afa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our predictions that used $\\log(\\text{Horsepower})$ as an input don't fall on a straight line. We shouldn't expect them to; the red dots come from:\n",
    "\n",
    "$$\\text{Predicted MPG} = 108.698 - 18.582 \\cdot \\log(\\text{Horsepower})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.intercept_, car_model_log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7081a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantitative scaling\n",
    "\n",
    "Until now, feature transformations we've discussed so far have involved converting **categorical** variables into **quantitative** variables. However, our log transformation was an example of transforming a **quantitative** variable into a new **quantitative** variable; this practice is called quantitative scaling.\n",
    "\n",
    "- **Standardization**: $x_i \\rightarrow \\frac{x_i - \\bar{x}}{\\sigma_x}$.\n",
    "- **Linearization via a non-linear transformation**: e.g. $\\text{log}$ and $\\text{sqrt}$. See Lab 8 for more.\n",
    "- **Discretization:** Convert data into percentiles (or more generally, quantiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101d553",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e65dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The `LinearRegression` class in `sklearn.linear_model` provides an implementation of least squares linear regression that works with multiple features.\n",
    "- To transform a categorical nominal variable into a quantitative variable, use **one hot** encoding.\n",
    "- To transform a categorical ordinal variable into a quantitative variable, use an **ordinal** encoding.\n",
    "- Quantitative feature transformations allow us to use linear models to model non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6e3a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- Performing one hot encoding and other feature engineering steps in `sklearn` directly. \n",
    "- Using `sklearn` `Pipeline`s to engineer features and fit models all through a single object."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
