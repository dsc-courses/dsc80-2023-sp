{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 ‚Äì Grouping, Pivoting, and Combining\n",
    "\n",
    "## DSC 80, Spring 2023\n",
    "\n",
    "### Due Date: Monday, April 24th at 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Welcome to the third lab assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2023-wi).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- **To ensure that all of your work to be submitted is in `lab.py`, we've provided an additional uneditable notebook, called `lab-validation.ipynb`, that contains only the tests and their setup. Make sure you are able to run it top-to-bottom without error before submitting!**\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Grouping\n",
    "\n",
    "Last year, the UK üá¨üáß announced a new [\"High Potential Individual\" visa](https://www.lexology.com/library/detail.aspx?g=41fa64ec-9272-468c-bdcb-8002745a754f), which allows graduates of universities ranked in the Top 50 globally to move to the UK without a job lined up. This visa has been a subject of much debate, in part due to how much rankings play a role. (Rest assured, UCSD is on the list!)\n",
    "\n",
    "In this section, you will analyze a dataset of university rankings, collected from  [here](https://www.kaggle.com/datasets/mylesoneill/world-university-rankings?datasetId=) (though we have pre-processed and modified the original dataset for the purposes of this question). Our version of the dataset is stored in `data/universities_unified.csv`.\n",
    "\n",
    "Columns:\n",
    "* `'world_rank'`: world rank of the institution\n",
    "* `'institution'`: name of the institution\n",
    "* `'national_rank'`: rank within the nation, formatted as `'country, rank'`\n",
    "* `'quality_of_education'`: rank by quality of education\n",
    "* `'alumni_employment'`: rank by alumni employment\n",
    "* `'quality_of_faculty'`: rank by quality of faculty\n",
    "* `'publications'`: rank by publications\n",
    "* `'influence'`: rank by influence\n",
    "* `'citations'`: rank by number of citations\n",
    "* `'broad_impact'`: rank by broad impact\n",
    "* `'patents'`: rank by number of patents\n",
    "* `'score'`: overall score of the institution, out of 100\n",
    "* `'control'`: whether the university is public or private\n",
    "* `'city'`: city in which the institution is located\n",
    "* `'state'`: state in which the institution is located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì Rankings 1Ô∏è‚É£\n",
    "\n",
    "There are (still) a few aspects of the dataset we need to clean before it's ready for analysis.\n",
    "\n",
    "As you work on this question, keep in mind that **you cannot use `for`-loops**. You shouldn't need to ‚Äì use vectorized `pandas` methods instead.\n",
    "\n",
    "#### `clean_universities`\n",
    "\n",
    "Complete the implementation of the function `clean_universities`, which takes in the raw rankings DataFrame and returns a cleaned DataFrame, cleaned according to the following information:\n",
    "\n",
    "- Some `'institution'` names contain `'\\n'` characters (e.g. `'University of California\\nSan Diego'`). Replace all instances of `'\\n'` with `', '` (a comma and a space) in the `'institution'` column.\n",
    "\n",
    "- Change the data type of the `'broad_impact'` column to `int`.\n",
    "\n",
    "* Split `'national_rank'` into two columns, `'nation'` and `'national_rank_cleaned'`, where:\n",
    "    * `'nation'` is the country (or its dependency) indicated in the first part of `'national_rank'`. \n",
    "        * Note that there are **3** countries that appear under different names for different schools. For all 3 of these countries, you should pick **the name that is longer** and use that name for every occurrence of the country. One of the 3 countries is **`'Czech Republic'`**, which also appears as **`'Czechia'`** ‚Äì since these refer to the same country and `'Czech Republic'` is longer, all instances of either name should be replaced with `'Czech Republic'`. You need to find the other 2 countries on your own. \n",
    "        * As is mentioned below, your function will only be tested on the DataFrame in `data/universities_unified.csv`, so you only need to change these 3 country names.\n",
    "    * `'national_rank_cleaned'` is the integer in the latter part of `'national_rank'`. Make sure that the data type of this column is `int`. \n",
    "    * Don't include the original `'national_rank'` column in the output DataFrame.\n",
    "* Create a Boolean column `'is_r1_public'`. This column should contain `True` if a university is public and classified as R1 and `False` otherwise. Treat `np.NaN`s as False. **Note that in the raw DataFrame, a university is classified as R1 if and only if it has non-null values in all of the following columns: `'control'`, `'city'`, and `'state'`.**\n",
    "    - Read [this page](https://en.wikipedia.org/wiki/List_of_research_universities_in_the_United_States) to learn more about what it means for a university to be classified as R1.\n",
    "    \n",
    "**The only dataset your function will be tested on is `data/universities_unified.csv`; you don't need to worry about other hidden test sets.** In addition, please return a *copy* of the original DataFrame; don't modify the original.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, we can do some basic exploration.\n",
    "\n",
    "#### `university_info`\n",
    "\n",
    "Complete the implementation of the function `university_info`, which takes in the **cleaned** DataFrame outputted by `clean_universities` and returns the following values in a list:\n",
    "* Among `'state(s)'` with three or more `'institution(s)'` in the dataset, the `'state'` whose universities have the lowest mean `'score'`.\n",
    "* The proportion of the `'institution(s)'` in the top 100 for which the `'quality of faculty'` ranking is also in the top 100.\n",
    "* The number of `'state(s)'` where at least 50% of the `'institution(s)'` are private (i.e. have an `'is_r1_public'` of `False`).\n",
    "* The lowest ranking `'institution'`, according to `'world_rank'`, that is ranked #1 in its nation (i.e. that has a `'national_rank_cleaned'` of 1).\n",
    "\n",
    "You can assume there are no ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'universities_unified.csv')\n",
    "df = pd.read_csv(fp)\n",
    "cleaned = clean_universities(df)\n",
    "info = university_info(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì High Standards ‚Ñ¢Ô∏è \n",
    "\n",
    "At various points in this question, you'll need to compute the standard deviation. As we saw in [Lecture 3](https://dsc80.com/resources/lectures/lec03/lec03.html#Aside:-std), `numpy` and `pandas` use different formulas by default to calculate the standard deviation; throughout, make sure you use the `ddof=0` argument when calculating standard deviations.\n",
    "\n",
    "\n",
    "#### `std_scores_by_nation` \n",
    "\n",
    "Complete the implementation of the function `std_scores_by_nation`, which takes in a **cleaned** DataFrame, like the one returned by `clean_universities`, and outputs a DataFrame: \n",
    "- with the same rows as the input, \n",
    "- with three columns: `'institution'`, `'nation'`, and `'score'` (in that order),\n",
    "- where the `'score'` column is **standardized** by `'nation'` - that is, the `'score'`s for each country are converted to standard units, using the mean and standard deviation of the `'score'`s for that country. If a `'score'` is `np.NaN`, leave it as `np.NaN`.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `su_and_spread`\n",
    "\n",
    "Lastly, complete the implementation of the function `su_and_spread`, which returns the answers to the following two questions, as a list.\n",
    "\n",
    "****Part 1****\n",
    "\n",
    "Let's compare rankings between two countries ‚Äì the US üá∫üá∏ and Canada üá®üá¶. There are in total $n$ universities in the US and $m$ universities in Canada. Suppose $x_1, x_2, ..., x_n$ are the `'world_rank'`s for US universities in **increasing order**, meaning that $x_1$ is the `'world_rank'` of the \"best\" US university. Similarly, $y_1, y_2, ..., y_m$ are the `'world_rank'`s for Canadian universities, also in increasing order. \n",
    "\n",
    "Suppose we take the aforementioned `'world_rank'`s and sort them together in **increasing order**, e.g. $x_1, x_2, y_1, x_3, ...$. **We define $R$ to be the average of the positions of the $x$ values.**\n",
    "\n",
    "For example, if there are 3 US universities (so $n=3$) and 2 Canadian universities ($m=2$), and\n",
    "  \n",
    "$$x_1 = 1, x_2 = 3, x_3 = 10, \\:\\:\\:\\: y_1 = 5, y_2 = 15$$\n",
    "\n",
    "When we sort the rankings in increasing order, we'd get 1, 3, 5, 10, 15, which correspond to the values $x_1, x_2, y_1, x_3, y_2$. The $x$ values are at positions 1, 2, and 4. Then, $R = \\frac{1 + 2 + 4}{3} = \\frac{7}{3}$. (Note that this is **not** the average of 1, 3, and 10).\n",
    "\n",
    "\n",
    "**Question:** If we believe that US universities in general rank higher than Canadian universities, should $R$ be\n",
    "1. larger than $\\frac{m + n}{2}$?\n",
    "2. smaller than $\\frac{m + n}{2}$?\n",
    "3. equal to $\\frac{m + n}{2}$?\n",
    "\n",
    "\n",
    "Store your answer ‚Äì either 1, 2, or 3 ‚Äì in the first element of `su_and_spread`'s output list. Note that this is a classical example of a non-parametric hypothesis test called a rank test.\n",
    "\n",
    "<br>\n",
    "\n",
    "****Part 2****\n",
    "\n",
    "Which `'nation'` has the largest variation in `'score'`s before standardization? Store your answer in the second element of `su_and_spread`'s output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "fp = os.path.join('data', 'universities_unified.csv')\n",
    "universities = pd.read_csv(fp)\n",
    "cleaned = clean_universities(universities)\n",
    "universities_out = std_scores_by_nation(cleaned)\n",
    "su_and_spread_out = su_and_spread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 ‚Äì Making Connections ü§ù\n",
    "\n",
    "A group of students decided to send out a survey to their connections on LinkedIn. Each student asks 1000 of their connections for their first and last name, the company they currently work at, their job title, their email, and the university they attended.\n",
    "\n",
    "**Your job is to combine all the data contained in the files `survey*.csv` (stored within the `data/responses` folder) into a single DataFrame. The number of files and the number of rows in each file may vary, so don't hardcode your answers!** To do so, implement the following two functions.\n",
    "\n",
    "#### `read_linkedin_survey`\n",
    "\n",
    "Complete the implementation of the function `read_linkedin_survey`, which takes in a string describing the path to a folder containing `survey*.csv` files and outputs a DataFrame with six columns titled `'first name'`, `'last name'`, `'current company'`, `'job title'`, `'email'`, and `'university'` (in that order) containing the survey information for all files combined. Make sure to reset the index of the combined DataFrame before returning it so that the index is unique. \n",
    "\n",
    "***Hints***:\n",
    "\n",
    "- Take a look at a few of the files in the `responses` folder. You may have to do some data cleaning to combine the DataFrames!\n",
    "\n",
    "- You can list the files in a directory using `os.listdir`.\n",
    "\n",
    "***Note***: Remember to use `os.path.join` to build file paths; do not use `'\\'` or `'\\\\'` or `'/'` manually.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `com_stats`\n",
    "\n",
    "Complete the implementation of the function `com_stats`, which takes in a DataFrame returned by `read_linkedin_survey` and returns a list containing, in the following order: \n",
    "- The proportion of people who went to a university with the string `'Ohio'` in its name that have the string `'Nurse'` somewhere in their job title.\n",
    "- The number of job titles that **end** with the string `'Engineer'`, not the number of people.\n",
    "- The job title that has the longest name (there are no ties).\n",
    "- The number of people who have the word `'manager'` in their job title, uppercase or lowercase (`'Manager'`, `'manager'`, and `'mANAgeR'` should all count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "dirname = os.path.join('data', 'responses')\n",
    "q3_out = read_linkedin_survey(dirname)\n",
    "stats_out = com_stats(q3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ‚Äì Survey Says... üë®‚Äçüë©‚Äçüëß‚Äçüë¶\n",
    "\n",
    "Professor Karthikeya often sends out extra credit surveys asking students for their favorite animals, movies, and other favorite things. These surveys are stored in the `data/extra-credit-surveys` folder. Each file in that folder corresponds to a different survey question (except for `favorite1.csv`, which contains students' names and IDs).\n",
    "\n",
    "Here's how extra credit works:\n",
    "- Each student who has completed at least 50% of the survey questions receives 5 points of extra credit.\n",
    "- If there is at least one survey question that at least 80% of the class answered (e.g. favorite animal), **everyone** in the class receives 1 point of extra credit. This overall class extra credit only applies twice, so if for example 95% of students answer the favorite color survey question and 91% answer the favorite animal survey question, and and 97% answer the favorite movie question, the entire class still receives 2 extra point as a class, not 3.\n",
    "- Note that this means that the most extra credit any student can earn is 7 points.\n",
    "\n",
    "#### `read_student_surveys`\n",
    "\n",
    "Complete the implementation of the function `read_student_surveys` which takes in a string describing the path to a folder containing `favorite*.csv` files and outputs a DataFrame containing all of the survey data combined, indexed by student ID (a value 1-1000).\n",
    "\n",
    "***Note***: Remember to use `os.path.join` to build file paths; do not use `'\\'` or `'\\\\'` or `'/'` manually.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `check_credit`\n",
    "\n",
    "Complete the implementation of the function `check_credit` which takes in a DataFrame returned by `read_student_surveys` and outputs a DataFrame indexed by student ID (a value 1-1000) with two columns:\n",
    "- `'name'`, containing the name of each student, and\n",
    "- `'ec'`, containing the number of extra credit points each student earned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "q4_out = read_student_surveys(dirname)\n",
    "check_credit_out = check_credit(q4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 ‚Äì Paw Patrol üêæ\n",
    "\n",
    "You are analyzing data from a veterinarian clinic. The datasets contain several types of information from the clinic, including its customers (pet owners), pets, available procedures, and procedure history. The column names are self-explanatory. These DataFrames are provided to you:\n",
    "-  `owners` stores the customer information, where every `'OwnerID'` is unique (verify this yourself).\n",
    "-  `pets` stores the pet information. Each pet belongs to a customer in `owners`.\n",
    "-  `procedure_detail` contains a catalog of procedures that are offered by the clinic.\n",
    "-  `procedure_history` has procedure records. Most procedures were given to a pet in `pets`.\n",
    "\n",
    "Complete the implementation of the following three functions, which each ask you to answer a specific question.\n",
    "\n",
    "#### `most_popular_procedure`\n",
    "\n",
    "What is the most popular `'ProcedureType'` amongst all pets in the `pets` DataFrame? Complete the implementation of the function `most_popular_procedure`, which takes in two DataFrames, `pets` and `procedure_history`, and returns the name of the most popular `'ProcedureType'` as a string.\n",
    "\n",
    "Note that some pets are registered but haven't had any procedures performed. Also, some pets that have had procedures done are not registered in `pets`.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `pet_name_by_owner`\n",
    "\n",
    "What is the name of each customer's pet(s)? Complete the implementation of the function `pet_name_by_owner`, which takes in two DataFrames, `owners` and `pets`, and returns a Series whose index contains owner first names, and whose values are pet names as **strings**. If an owner has multiple pets, the value corresponding to that owner should instead be a **list of pet names as strings**.\n",
    "\n",
    "Note that owner first names are not necessarily unique, and so the Series you return will not necessarily have a unique index.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `total_cost_per_city`\n",
    "\n",
    "Note that the `owners` DataFrame has a `'City'` column, describing the city in which each pet owner and their pets live. How much did each city spend in total on procedures? Complete the implementation of the function `total_cost_per_city`, which takes in four DataFrames, `owners`, `pets`, `procedure_history`, and `procedure_detail`, and returns a Series indexed by `'City'` that describes the total amount that each city has spent on pets' procedures.\n",
    "\n",
    "***Hint:*** At some point, you may have to merge on multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "procedure_detail_fp = os.path.join('data', 'pets', 'ProceduresDetails.csv')\n",
    "pets = pd.read_csv(pets_fp)\n",
    "procedure_history = pd.read_csv(procedure_history_fp)\n",
    "owners = pd.read_csv(owners_fp)\n",
    "procedure_detail = pd.read_csv(procedure_detail_fp)\n",
    "\n",
    "out_01 = most_popular_procedure(pets, procedure_history)\n",
    "out_02 = pet_name_by_owner(owners, pets)\n",
    "out_03 = total_cost_per_city(owners, pets, procedure_history, procedure_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 ‚Äì Summarizing Sales üí∞\n",
    "\n",
    "Recall from [Lecture 5](https://dsc80.com/resources/lectures/lec05/lec05.html), a pivot table allows you to aggregate the entries in a DataFrame based on two categorical columns. In this question, you are given a simple dataset, `data/sales.csv`, and are asked to solve a few simple problems using the `pivot_table` method. \n",
    "\n",
    "**We have provided outlines for the DataFrames you need to create, but yours may have a different number of rows and columns and different values.**\n",
    "\n",
    "**`for loops` are not allowed in this question.**\n",
    "\n",
    "#### `average_seller`\n",
    "\n",
    "Complete the implementation of the function `average_seller`, which takes in the `sales` DataFrame and returns a DataFrame that contains the average sales for each seller, indexed by `'Name'` and containing the column `'Average Sales'`. There should not be any `NaN`s.\n",
    "\n",
    "***Note:*** You may be able to implement `average_seller` without using `pivot_table`.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Average Sales</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `product_name`\n",
    "\n",
    "Complete the implementation of the function `product_name` that takes in the `sales` DataFrame and returns a DataFrame that contains the total sales for each product, indexed by `'Name'`. Do not fill in `NaN`s.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th>boat</th>\n",
    "      <th>book</th>\n",
    "      <th>hotel</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Jones</th>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `count_product`\n",
    "\n",
    "Complete the implementation of the function `count_product` that takes in the `sales` DataFrame and returns a DataFrame that contains the total number of items sold product-wise and name-wise per date. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Date</th>\n",
    "      <th>01.01.2012</th>\n",
    "      <th>02.20.2013</th>\n",
    "      <th>02.25.2015</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>boat</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">book</th>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>hotel</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `total_by_month`\n",
    "\n",
    "Complete the implementation of the function `total_by_month` that takes in the `sales` DataFrame and returns a pivot table that contains the total sales name-wise, product-wise per month. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Month</th>\n",
    "      <th>February</th>\n",
    "      <th>January</th>\n",
    "      <th>July</th>\n",
    "      <th>March</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th>Product</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Jones</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Smith</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***Note:*** [Here](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html) is another great resource that provides an overview of `pivot_table` with many examples from the Titanic dataset.\n",
    "\n",
    "<span style=\"color:red\"> ***Important:***</span> You can't use loop by any means in this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'sales.csv')\n",
    "sales = pd.read_csv(fp)\n",
    "q6_average_seller_out = average_seller(sales)\n",
    "q6_product_name_out = product_name(sales)\n",
    "q6_product_count_out = count_product(sales)\n",
    "q6_total_by_month_out = total_by_month(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done with Lab 3! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To verify that all of your work is indeed in `lab.py`, and that you didn't accidentally implement a function in this notebook and not in `lab.py`, we've included another notebook in the lab folder, called `lab-validation.ipynb`. `lab-validation.ipynb` is a version of this notebook with only the `grader.check` cells and the code needed to set up the tests. \n",
    "\n",
    "### **Go to `lab-validation.ipynb`, and go to Kernel > Restart & Run All.** This will check if all `grader.check` test cases pass using just the code in `lab.py`.\n",
    "\n",
    "Once you're able to pass all test cases in `lab-validation.ipynb`, including the call to `grader.check_all()` at the very bottom, then you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cleaned.shape[0] == df.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> cleaned['nation'].nunique() == 59\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(info) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all([isinstance(x, y) for x, y in zip(info, [str, float, int, str])])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (info[1] >= 0) & (info[1] <= 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> universities_out.shape[0] == cleaned.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all(universities_out.columns == ['institution', 'nation', 'score'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.all(abs(universities_out.select_dtypes(include='number').mean()) < 10**-7)  # standard units should average to 0!\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(su_and_spread_out) == 2\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> su_and_spread_out[0] in np.arange(1, 4)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(su_and_spread_out[1], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q3_out, pd.DataFrame) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(q3_out) == 5000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_linkedin_survey('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(stats_out) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[0], float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[1], int)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[2], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q4_out, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out.shape == (1000, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_student_surveys('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out.shape == (1000, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out['ec'].max() == 6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_01, str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(out_02) == len(owners)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Sarah' in out_02.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Cookie' in out_02.values\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(out_03.index) <= set(owners['City'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q6_average_seller_out.shape[0] == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q6_average_seller_out[\"Average Sales\"].sum() < 5000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q6_product_name_out.size == 15\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q6_product_name_out[\"pen\"].isnull().sum() == 0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q6_product_count_out.size == 70\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q6_total_by_month_out.shape[1] == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> int(q6_product_name_out['hotel'].isnull().sum()) == 2\nTrue",
         "failure_message": "null values: hotel row",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_product_count_out.shape == (10, 7)\nTrue",
         "failure_message": "correct shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q6_total_by_month_out > 2000).sum().sum() == 3\nTrue",
         "failure_message": "number of entries strictly over 2000",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (q6_total_by_month_out == 0).sum().sum() == 39\nTrue",
         "failure_message": "number of zero entries",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
